/**
 * Recovery Script Generator
 * Generates custom recovery scripts for downloading websites from Wayback Machine
 */

import { WaybackSnapshot } from '../external-apis/wayback';

export type ScriptType = 'bash' | 'nodejs' | 'python';

export interface ScriptConfig {
  domain: string;
  snapshotDate: string;
  bestSnapshot: WaybackSnapshot;
  totalSnapshots: number;
  estimatedPages: number;
  quality: string;
  includeAssets: boolean;
  includeSubdomains: boolean;
}

export class RecoveryScriptGenerator {
  /**
   * Generate Bash recovery script
   */
  generateBashScript(config: ScriptConfig): string {
    return `#!/usr/bin/env bash
# =============================================================================
# Website Recovery Script for ${config.domain}
# Generated by Find My Website on ${new Date().toISOString().split('T')[0]}
# =============================================================================

set -e  # Exit on error

DOMAIN="${config.domain}"
OUTPUT_DIR="./recovered-\${DOMAIN//./-}"
SNAPSHOT_DATE="${config.snapshotDate}"

echo "=================================="
echo "Recovering: $DOMAIN"
echo "Using snapshot from: $SNAPSHOT_DATE"
echo "Estimated pages: ${config.estimatedPages}"
echo "Quality: ${config.quality}"
echo "=================================="

# Step 1: Check dependencies
echo ""
echo "Step 1: Checking dependencies..."
if ! command -v ruby &> /dev/null; then
    echo "‚ùå Ruby not found. Please install Ruby first:"
    echo "   macOS: brew install ruby"
    echo "   Linux: sudo apt-get install ruby"
    exit 1
fi

if ! command -v wayback_machine_downloader &> /dev/null; then
    echo "‚öôÔ∏è  Installing wayback-machine-downloader..."
    gem install wayback_machine_downloader
fi
echo "‚úÖ Dependencies OK"

# Step 2: Download from Wayback Machine
echo ""
echo "Step 2: Downloading site from Wayback Machine..."
echo "‚è≥ This may take several minutes depending on site size..."
echo ""

wayback_machine_downloader $DOMAIN \\
  --from $SNAPSHOT_DATE \\
  --to $SNAPSHOT_DATE \\
  --directory $OUTPUT_DIR \\
  ${config.includeAssets ? '--all \\' : ''}
  --concurrency 1

# Step 3: Clean up archive.org references
echo ""
echo "Step 3: Cleaning up Wayback Machine references..."

# Remove wayback machine paths from HTML
find $OUTPUT_DIR -name "*.html" -type f -exec sed -i.bak \\
  's|https://web\\.archive\\.org/web/[0-9]*||g' {} \\;

# Remove Wayback toolbar
find $OUTPUT_DIR -name "*.html" -type f -exec sed -i.bak \\
  '/<!-- BEGIN WAYBACK TOOLBAR INSERT -->/,/<!-- END WAYBACK TOOLBAR INSERT -->/d' {} \\;

# Remove backup files
find $OUTPUT_DIR -name "*.bak" -delete

echo "‚úÖ Cleanup complete"

# Step 4: Generate report
echo ""
echo "Step 4: Generating recovery report..."

cat > $OUTPUT_DIR/RECOVERY_REPORT.txt << 'EOF'
Website Recovery Report
=======================
Domain: ${config.domain}
Snapshot Date: ${config.snapshotDate}
Recovery Date: $(date)
Output Directory: $OUTPUT_DIR
Quality Assessment: ${config.quality}

Files Recovered:
- HTML Pages: $(find $OUTPUT_DIR -name "*.html" 2>/dev/null | wc -l)
- Images: $(find $OUTPUT_DIR -type f \\( -name "*.jpg" -o -name "*.png" -o -name "*.gif" \\) 2>/dev/null | wc -l)
- CSS Files: $(find $OUTPUT_DIR -name "*.css" 2>/dev/null | wc -l)
- JavaScript Files: $(find $OUTPUT_DIR -name "*.js" 2>/dev/null | wc -l)

Next Steps:
===========
1. Review the content in: $OUTPUT_DIR
2. Test locally:
   cd $OUTPUT_DIR && python3 -m http.server 8000
3. Visit: http://localhost:8000
4. Fix any broken links or missing assets
5. Update contact information
6. Deploy to your hosting provider

Common Issues to Check:
=======================
- Absolute URLs pointing to old domain
- Missing images or assets
- Broken internal links
- Outdated contact information
- Analytics/tracking codes to update
- Forms that need backend implementation

Deployment Options:
===================
1. Netlify: Drag & drop the folder to netlify.com/drop
2. Vercel: Run 'vercel' in the directory
3. GitHub Pages: Push to GitHub and enable Pages
4. Traditional hosting: Upload via FTP/SFTP

Support:
========
For help deploying your recovered site:
- Visit: findmywebsite.com/help
- Docs: findmywebsite.com/docs/recovery

Generated by Find My Website - findmywebsite.com
EOF

echo ""
echo "‚úÖ Recovery complete!"
echo ""
echo "üìÅ Files saved to: $OUTPUT_DIR"
echo "üìÑ See full report: $OUTPUT_DIR/RECOVERY_REPORT.txt"
echo ""
echo "üöÄ Next steps:"
echo "   1. cd $OUTPUT_DIR"
echo "   2. Review the content"
echo "   3. Test locally: python3 -m http.server 8000"
echo "   4. Deploy to your hosting"
echo ""
echo "Need help? Visit findmywebsite.com/help"
echo ""
`;
  }

  /**
   * Generate Node.js recovery script
   */
  generateNodeScript(config: ScriptConfig): string {
    return `#!/usr/bin/env node
/**
 * Advanced Website Recovery Script for ${config.domain}
 * Generated by Find My Website
 */

const { execSync } = require('child_process');
const fs = require('fs').promises;
const path = require('path');

const CONFIG = {
  domain: '${config.domain}',
  snapshotDate: '${config.snapshotDate}',
  outputDir: './recovered-${config.domain.replace(/\./g, '-')}',
  estimatedPages: ${config.estimatedPages},
  quality: '${config.quality}',
};

class WebsiteRecovery {
  constructor(config) {
    this.config = config;
    this.stats = {
      pagesDownloaded: 0,
      assetsDownloaded: 0,
      startTime: Date.now(),
    };
  }

  async run() {
    console.log('üîÑ Starting website recovery...\\n');

    try {
      await this.printHeader();
      await this.checkDependencies();
      await this.downloadSite();
      await this.cleanContent();
      await this.generateReport();
      await this.printSummary();
    } catch (error) {
      console.error('‚ùå Recovery failed:', error.message);
      process.exit(1);
    }
  }

  async printHeader() {
    console.log('='.repeat(60));
    console.log('      Website Recovery Tool - Find My Website');
    console.log('='.repeat(60));
    console.log(\`\\nDomain: \${this.config.domain}\`);
    console.log(\`Snapshot: \${this.config.snapshotDate}\`);
    console.log(\`Quality: \${this.config.quality}\`);
    console.log(\`Estimated pages: \${this.config.estimatedPages}\`);
    console.log('='.repeat(60) + '\\n');
  }

  async checkDependencies() {
    console.log('üìã Checking dependencies...');

    try {
      execSync('wayback_machine_downloader --version', { stdio: 'ignore' });
      console.log('‚úÖ wayback_machine_downloader found\\n');
    } catch {
      console.log('‚öôÔ∏è  Installing wayback_machine_downloader...');
      execSync('gem install wayback_machine_downloader', { stdio: 'inherit' });
      console.log('‚úÖ Installation complete\\n');
    }
  }

  async downloadSite() {
    console.log('‚¨áÔ∏è  Downloading from Wayback Machine...');
    console.log('   This may take several minutes...\\n');

    const cmd = \`wayback_machine_downloader \${this.config.domain} \\
      --from \${this.config.snapshotDate} \\
      --to \${this.config.snapshotDate} \\
      --directory \${this.config.outputDir} \\
      ${config.includeAssets ? '--all \\' : ''}
      --concurrency 1\`;

    execSync(cmd, { stdio: 'inherit' });
    console.log('\\n‚úÖ Download complete\\n');
  }

  async cleanContent() {
    console.log('üßπ Cleaning content...');

    const files = await this.findFiles(this.config.outputDir, '.html');

    for (const file of files) {
      let content = await fs.readFile(file, 'utf8');

      // Remove Wayback Machine toolbar
      content = content.replace(
        /<!-- BEGIN WAYBACK TOOLBAR INSERT -->.*?<!-- END WAYBACK TOOLBAR INSERT -->/gs,
        ''
      );

      // Remove archive.org references
      content = content.replace(/https?:\\/\\/web\\.archive\\.org\\/web\\/\\d+\\//g, '/');

      await fs.writeFile(file, content);
      this.stats.pagesDownloaded++;
    }

    console.log(\`‚úÖ Cleaned \${files.length} HTML files\\n\`);
  }

  async findFiles(dir, ext) {
    const files = [];

    const walk = async (directory) => {
      const entries = await fs.readdir(directory, { withFileTypes: true });

      for (const entry of entries) {
        const fullPath = path.join(directory, entry.name);

        if (entry.isDirectory()) {
          await walk(fullPath);
        } else if (entry.name.endsWith(ext)) {
          files.push(fullPath);
        }
      }
    };

    await walk(dir);
    return files;
  }

  async generateReport() {
    console.log('üìÑ Generating recovery report...');

    const report = \`
Website Recovery Report
${'='.repeat(60)}

Domain: \${this.config.domain}
Snapshot Date: \${this.config.snapshotDate}
Recovery Date: \${new Date().toISOString()}
Quality: \${this.config.quality}

Recovery Statistics:
- Pages: \${this.stats.pagesDownloaded}
- Duration: \${((Date.now() - this.stats.startTime) / 1000).toFixed(2)}s

Next Steps:
1. Review the content
2. Test locally: cd \${this.config.outputDir} && python3 -m http.server 8000
3. Fix any issues
4. Deploy to hosting

Generated by Find My Website - findmywebsite.com
${'='.repeat(60)}
    \`.trim();

    const reportPath = path.join(this.config.outputDir, 'RECOVERY_REPORT.txt');
    await fs.writeFile(reportPath, report);

    console.log(\`‚úÖ Report saved to \${reportPath}\\n\`);
  }

  async printSummary() {
    const duration = ((Date.now() - this.stats.startTime) / 1000).toFixed(2);

    console.log('='.repeat(60));
    console.log('                 RECOVERY COMPLETE!');
    console.log('='.repeat(60));
    console.log(\`\\n‚úÖ Pages recovered: \${this.stats.pagesDownloaded}\`);
    console.log(\`‚è±Ô∏è  Time taken: \${duration} seconds\`);
    console.log(\`\\nüìÅ Output: \${this.config.outputDir}\`);
    console.log('\\nüöÄ Next: Test with python3 -m http.server 8000');
    console.log('\\n' + '='.repeat(60));
  }
}

const recovery = new WebsiteRecovery(CONFIG);
recovery.run().catch(console.error);
`;
  }

  /**
   * Generate Python recovery script
   */
  generatePythonScript(config: ScriptConfig): string {
    return `#!/usr/bin/env python3
"""
Website Recovery Tool for ${config.domain}
Generated by Find My Website
"""

import os
import sys
import subprocess
import re
from pathlib import Path
from datetime import datetime

CONFIG = {
    'domain': '${config.domain}',
    'snapshot_date': '${config.snapshotDate}',
    'output_dir': './recovered-${config.domain.replace(/\./g, '-')}',
    'estimated_pages': ${config.estimatedPages},
    'quality': '${config.quality}',
}

class WebsiteRecoveryTool:
    def __init__(self, config):
        self.config = config
        self.stats = {
            'start_time': datetime.now(),
            'pages': 0,
            'images': 0,
        }

    def run(self):
        try:
            self.print_header()
            self.check_dependencies()
            self.download_site()
            self.clean_content()
            self.generate_report()
            self.print_summary()
        except Exception as e:
            print(f"\\n‚ùå Recovery failed: {e}")
            sys.exit(1)

    def print_header(self):
        print("=" * 60)
        print("      Website Recovery Tool - Find My Website")
        print("=" * 60)
        print(f"\\nDomain: {self.config['domain']}")
        print(f"Snapshot: {self.config['snapshot_date']}")
        print(f"Quality: {self.config['quality']}")
        print("=" * 60 + "\\n")

    def check_dependencies(self):
        print("üìã Checking dependencies...")

        try:
            subprocess.run(['wayback_machine_downloader', '--version'],
                         capture_output=True, check=True)
            print("‚úÖ wayback_machine_downloader found\\n")
        except:
            print("‚öôÔ∏è  Installing wayback_machine_downloader...")
            subprocess.run(['gem', 'install', 'wayback_machine_downloader'],
                         check=True)
            print("‚úÖ Installation complete\\n")

    def download_site(self):
        print("‚¨áÔ∏è  Downloading from Wayback Machine...")
        print("   This may take several minutes...\\n")

        cmd = [
            'wayback_machine_downloader',
            self.config['domain'],
            '--from', self.config['snapshot_date'],
            '--to', self.config['snapshot_date'],
            '--directory', self.config['output_dir'],
            ${config.includeAssets ? "'--all'," : ''}
            '--concurrency', '1'
        ]

        subprocess.run(cmd, check=True)
        print("\\n‚úÖ Download complete\\n")

    def clean_content(self):
        print("üßπ Cleaning content...")

        output_path = Path(self.config['output_dir'])

        for html_file in output_path.rglob('*.html'):
            with open(html_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Remove Wayback toolbar
            content = re.sub(
                r'<!-- BEGIN WAYBACK TOOLBAR INSERT -->.*?<!-- END WAYBACK TOOLBAR INSERT -->',
                '', content, flags=re.DOTALL
            )

            # Fix URLs
            content = re.sub(r'https?://web\\.archive\\.org/web/\\d+/', '/', content)

            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(content)

            self.stats['pages'] += 1

        print(f"‚úÖ Cleaned {self.stats['pages']} pages\\n")

    def generate_report(self):
        print("üìÑ Generating report...")

        report = f"""
Website Recovery Report
{'=' * 60}

Domain: {self.config['domain']}
Snapshot Date: {self.config['snapshot_date']}
Recovery Date: {datetime.now().isoformat()}

Pages recovered: {self.stats['pages']}

Next Steps:
1. Review content
2. Test: python3 -m http.server 8000
3. Deploy

Generated by Find My Website
{'=' * 60}
        """.strip()

        report_path = Path(self.config['output_dir']) / 'RECOVERY_REPORT.txt'
        report_path.write_text(report)

        print(f"‚úÖ Report saved\\n")

    def print_summary(self):
        duration = (datetime.now() - self.stats['start_time']).total_seconds()

        print("=" * 60)
        print("                 RECOVERY COMPLETE!")
        print("=" * 60)
        print(f"\\n‚úÖ Pages: {self.stats['pages']}")
        print(f"‚è±Ô∏è  Time: {duration:.1f}s")
        print(f"\\nüìÅ Output: {self.config['output_dir']}")
        print("=" * 60)

if __name__ == '__main__':
    tool = WebsiteRecoveryTool(CONFIG)
    tool.run()
`;
  }

  /**
   * Generate script based on type
   */
  generate(config: ScriptConfig, scriptType: ScriptType): string {
    switch (scriptType) {
      case 'bash':
        return this.generateBashScript(config);
      case 'nodejs':
        return this.generateNodeScript(config);
      case 'python':
        return this.generatePythonScript(config);
      default:
        throw new Error(`Unknown script type: ${scriptType}`);
    }
  }

  /**
   * Generate all script types
   */
  generateAll(config: ScriptConfig): Record<ScriptType, string> {
    return {
      bash: this.generateBashScript(config),
      nodejs: this.generateNodeScript(config),
      python: this.generatePythonScript(config),
    };
  }
}

// Export singleton instance
export const scriptGenerator = new RecoveryScriptGenerator();
